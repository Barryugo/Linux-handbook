# Import modules
import os
import zipfile
from azureml.core import Workspace, Datastore, Dataset, Experiment, ScriptRunConfig, Environment, Model, ComputeTarget
from azureml.core.runconfig import DEFAULT_CPU_IMAGE
from azureml.train.hyperdrive import HyperDriveConfig, RandomParameterSampling, PrimaryMetricGoal, MedianStoppingPolicy
from azureml.widgets import RunDetails
import tensorflow as tf
import mlflow
import mlflow.tensorflow

# Create a workspace object
ws = Workspace.from_config()

# Get the default datastore object
datastore = ws.get_default_datastore()

# Download the MNIST dataset from tensorflow
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Save the training and test data as numpy arrays
np.save("x_train.npy", x_train)
np.save("y_train.npy", y_train)
np.save("x_test.npy", x_test)
np.save("y_test.npy", y_test)

# Create a zip file containing the data files
with zipfile.ZipFile("mnist.zip", "w") as zip:
    zip.write("x_train.npy")
    zip.write("y_train.npy")
    zip.write("x_test.npy")
    zip.write("y_test.npy")

# Upload the zip file to the default datastore
datastore.upload_files(files=["mnist.zip"],
                       target_path="mnist",
                       overwrite=True,
                       show_progress=True)

# Create a dataset from files in the datastore
dataset = Dataset.File.from_files(path=(datastore, "mnist/mnist.zip"))

# Register the dataset in the workspace
dataset = dataset.register(workspace=ws,
                           name="mnist",
                           description="MNIST dataset",
                           create_new_version=True)

# Create a compute cluster object
compute_target = ComputeTarget(workspace=ws, name="<your-cluster-name>")

# Define the hyperparameter search space
param_sampling = RandomParameterSampling({
    "--learning_rate": uniform(0.001, 0.1),
    "--batch_size": choice(16, 32, 64),
    "--epochs": choice(5, 10, 15)
})

# Define the primary metric and the goal
primary_metric_name = "accuracy"
primary_metric_goal = PrimaryMetricGoal.MAXIMIZE

# Define the early termination policy
early_termination_policy = MedianStoppingPolicy(evaluation_interval=1)

# Create a TensorFlow environment
tf_env = Environment(name="tf_env")
tf_env.python.user_managed_dependencies = False
tf_env.docker.enabled = True
tf_env.docker.base_image = DEFAULT_CPU_IMAGE
tf_env.python.conda_dependencies.add_pip_package("tensorflow==2.4.1")
tf_env.python.conda_dependencies.add_pip_package("mlflow")

# Create a script run configuration
src = ScriptRunConfig(source_directory=".",
                      script="train.py",
                      arguments=["--learning_rate", "--batch_size", "--epochs"],
                      compute_target=compute_target,
                      environment=tf_env)

# Create a hyperdrive configuration
hyperdrive_config = HyperDriveConfig(run_config=src,
                                     hyperparameter_sampling=param_sampling,
                                     primary_metric_name=primary_metric_name,
                                     primary_metric_goal=primary_metric_goal,
                                     max_total_runs=20,
                                     max_concurrent_runs=4,
                                     policy=early_termination_policy)

# Create an experiment object
experiment = Experiment(workspace=ws, name="hyperdrive_mnist")

# Submit the hyperdrive configuration to the experiment
hyperdrive_run = experiment.submit(hyperdrive_config)

# Create a RunDetails widget object and display it in the notebook
widget = RunDetails(hyperdrive_run)
widget.show()

# Wait for the hyperdrive experiment to complete
hyperdrive_run.wait_for_completion(show_output=True)

# Get the best run and its details
best_run = hyperdrive_run.get_best_run_by_primary_metric()
best_run_metrics = best_run.get_metrics()
best_run_parameters = best_run.get_details()["runDefinition"]["arguments"]

# Print the best run ID, metrics, and parameters
print(f"Best run ID: {best_run.id}")
print(f"Best run accuracy: {best_run_metrics['accuracy']}")
print(f"Best run learning rate: {best_run_parameters[1]}")
print(f"Best run batch size: {best_run_parameters[3]}")
print(f"Best run epochs: {best_run_parameters[5]}")

# Register the best model in the workspace
model = best_run.register_model(model_name="hyperdrive_mnist",
                                model_path="outputs/model",
                                description="CNN model for MNIST classification using hyperdrive",
                                tags={"type": "CNN", "dataset": "MNIST", "method": "hyperdrive"},
                                model_framework=Model.Framework.TENSORFLOW,
                                model_framework_version="2.4.1")
